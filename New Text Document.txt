1.Write a program to implement Huffman code using symbols with their corresponding 
robabilities.  
##
##
import heapq 
from collections import defaultdict, Counter 
 
def calculate_frequency(my_text): 
    my_text = my_text.upper().replace(' ', '') 
    frequency = dict(Counter(my_text)) 
    return frequency 
 
def build_heap(freq): 
    heap = [[weight, [char, ""]] for char, weight in freq.items()] 
    heapq.heapify(heap) 
    return heap 
 
def build_tree(heap): 
    while len(heap) > 1: 
        lo = heapq.heappop(heap) 
        hi = heapq.heappop(heap) 
        for pair in lo[1:]: 
            pair[1] = '0' + pair[1] 
        for pair in hi[1:]: 
            pair[1] = '1' + pair[1] 
        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:]) 
    return heap[0] 
 
freq = calculate_frequency("aaabbbbbccccccddddee") 
heap = build_heap(freq) 
tree = build_tree(heap) 
for pair in tree[1:]: 
    print(pair[0], '->', pair[1]) 

-------------------------------------------------------------------------------------
2.Write a program to simulate convolutional coding based on their encoder structure. 
##
##
import numpy as np 
def encode(msg, K, n): 
    g, v = [], [] 
    for i in range(n): 
        sub_g = list(map(int, input(f'Enter bits for generator {i}: ').split())) 
        if len(sub_g) != K: 
            raise ValueError(f'You entered {len(sub_g)} bits.\n need to enter {K} bits') 
        g.append(sub_g) 
    for i in range(n): 
        res = list(np.poly1d(g[i]) * np.poly1d(msg)) 
        v.append(res) 
 
    listMax = max(len(l) for l in v) 
    for i in range(n): 
        if len(v[i]) != listMax: 
            tmp = [0] * (listMax - len(v[i])) 
            v[i] = tmp + v[i] 
    res = [] 
    for i in range(listMax): 
        res += [v[j][i] % 2 for j in range(n)] 
    return res 
 
message = list(map(int, input('Enter message: ').split())) 
K = int(input('Constraints: ')) 
n = int(input('Number of output(generator): ')) 
print('Encoded Message', encode(message, K, n)) 
 
# message= 1 0 1 0 1 
# K=4 
# n=2 
# g0= 1 1 1 1 
# g1= 1 1 0 1 
# Encoded Message: 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 

-------------------------------------------------------------------------------------
3.rite a program to implement  Lempel-Ziv code. 
##
##
message = 'AABABBBABAABABBBABBABB' 
dictionary = {} 
tmp, i, last = '', 1, 0 
Flag = True 
for x in message: 
    tmp += x 
    Flag = False 
    if tmp not in dictionary.keys(): 
        dictionary[tmp] = i 
        tmp = '' 
        i += 1 
        Flag = True 
if not Flag: 
    last = dictionary[tmp] 
res = ['1'] 
for char, idx in list(dictionary.items())[1:]: 
    tmp, s = '', '' 
    for x, j in zip(char[:-1], range(len(char))): 
        tmp += x 
        if tmp in dictionary.keys(): 
            take = dictionary[tmp]
            s = str(take) + char[j + 1:] 
    if len(char) == 1: 
        s = char 
    res.append(s) 
if last: 
    res.append(str(last)) 
 
mark = { 
    'A': 0, 
    'B': 1 
} 
 
final_res = [] 
for x in res: 
    tmp = "" 
    for char in x: 
        if char.isalpha(): 
            tmp += bin(mark[char])[2:] 
        else: 
            tmp += bin(int(char))[2:] 
    final_res.append(tmp.zfill(4)) 
 
print(res) 
print("Encoded: ", final_res) 

--------------------------------------------------------------------------------------
4.Write a program to implement  Hamming code.  
##
##
def calculate_parity_bits(data_bits): 
    # Place data bits in positions 3, 5, 6, and 7 
    d3, d5, d6, d7 = map(int, data_bits) 
    # Calculate parity bits for even parity 
    # P1 covers positions 1, 3, 5, 7 
    p1 = (d3 + d5 + d7) % 2 
    # P2 covers positions 2, 3, 6, 7 
    p2 = (d3 + d6 + d7) % 2 
    # P4 covers positions 4, 5, 6, 7 
    p4 = (d5 + d6 + d7) % 2 
 
    # Return the encoded message 
    hamming_code = f"{p1}{p2}{d3}{p4}{d5}{d6}{d7}" 
    return hamming_code 
 
def detect_and_correct_error(received_data): 
    # Convert the received data to a list of integers for easier manipulation 
    received_bits = list(map(int, received_data)) 
 
    # Check parity for P1, P2, and P4 
    p1_check = (received_bits[0] + received_bits[2] + received_bits[4] + received_bits[6]) % 2 
    p2_check = (received_bits[1] + received_bits[2] + received_bits[5] + received_bits[6]) % 2 
    p4_check = (received_bits[3] + received_bits[4] + received_bits[5] + received_bits[6]) % 2 
 
    # Calculate the syndrome (error position) 
    error_position = p1_check * 1 + p2_check * 2 + p4_check * 4 
 
    if error_position == 0: 
        return "No error detected", received_data  # No error 
    else: 
        # Correct the error at the error_position 
        print(f"Error detected at position {error_position}. Correcting it.") 
        received_bits[error_position - 1] = 1 - received_bits[error_position - 1]  # Flip the erroneous bit 
        return "Error detected and corrected", received_bits 
 
# Example usage 
data_bits = "1011"  # Data bits to encode 
print(f"Data: {data_bits}") 
 
# Calculate the encoded message (Hamming code) 
encoded_data = calculate_parity_bits(data_bits) 
print(f"Encoded Data: {encoded_data}")
# Simulate a transmission with an error (let's say bit 6 has an error) 
received_data_with_error = "0110111"  # This is the received data with a single-bit error 
print(f"Received Data (with error): {received_data_with_error}") 
# Detect and correct errors 
status, corrected_data = detect_and_correct_error(received_data_with_error) 
print(status) 
print(f"Corrected Data: {''.join(map(str, corrected_data))}") 

-----------------------------------------------------------------------------------
5.A binary symmetric channel has the following noise matix with probability,  
P(X/Y)   = [23,13,13,23]  Now find the Channel Capacity C. 
##
##
import math 
# given 
matrix = [[2 / 3, 1 / 3], [1 / 3, 2 / 3]] 
print("Symmetric matrix is:") 
for i in range(0, 2): 
 for j in range(0, 2): 
  print('%.2f ' % matrix[i][j], end=' ') 
 print() 
# Calculate H(Y/X) using formula (1-p)log(1/(1-p))+plog(1/p) 
Hp = matrix[0][0] * math.log2(1.0 / matrix[0][0]) + matrix[0][1] * math.log2(1.0 / matrix[0][1]) 
print("Conditional probability H(Y/X) is = %.3f" % Hp, "bits/msg symbol") 
# Now calculate channel capacity using formula C = 1- H(Y/X) 
C = 1 - Hp 
print("Channel Capacity is = %.3f" % C, "bits/msg symbol") 

-----------------------------------------------------------------------------------------
6.Write a program to check the optimality of Huffman code.
##
##
import heapq 
import math 
from collections import Counter 
 
def calculate_frequency(my_text): 
    my_text = my_text.upper().replace(' ', '') 
    frequency = dict(Counter(my_text)) 
    return frequency 
 
def build_heap(freq): 
    heap = [[weight, [char, ""]] for char, weight in freq.items()] 
    heapq.heapify(heap) 
    return heap 
 
def build_tree(heap): 
    while len(heap) > 1: 
        lo = heapq.heappop(heap) 
        hi = heapq.heappop(heap) 
        for pair in lo[1:]: 
            pair[1] = '0' + pair[1] 
        for pair in hi[1:]: 
            pair[1] = '1' + pair[1] 
        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:]) 
    return heap[0] 
def compute_huffman_avg_length(freq, tree, length): 
    huffman_avg_length = 0 
    for pair in tree[1:]: 
        huffman_avg_length += (len(pair[1]) * (freq[pair[0]] / length)) 
    return huffman_avg_length 
 
def entropy(freq, length): 
    H = 0 
    P = [fre / length for _, fre in freq.items()] 
    for x in P: 
        H += -(x * math.log2(x)) 
    return H 
 
message = "aaabbbbbccccccddddee" 
freq = calculate_frequency(message) 
heap = build_heap(freq) 
tree = build_tree(heap) 
# tree=[20, ['D', '0'], ['B', '01'], ['E', '100'], ['A', '101'], ['C', '11']] not optimal 
huffman_avg_length = compute_huffman_avg_length(freq, tree, len(message)) 
H = entropy(freq, len(message)) 
print("Huffman : %.2f bits" % huffman_avg_length) 
print('Entropy : %.2f bits' % H) 
if huffman_avg_length >= H: 
    print("Huffman code is optimal") 
else: 
    print("Code is not optimal")

------------------------------------------------------------------------------------------------
7.Write a code to find the entropy rate of a random walk on the following weighted 
graph.(x1234,11211)
##
##
import math 
from collections import defaultdict 
 
# given 
g = defaultdict(list) 
xij = [[1, 1, 2], [1, 1], [1, 2, 1], [1, 1]] 
 
def makeGraph(li): 
    for node in range(len(li)): 
        for x in li[node]: 
            g[node].append(x) 
 
def entropy(li): 
    H = 0 
    for x in li: 
        if x == 0: 
            continue 
        H += -(x * math.log2(x)) 
    return H 
 
# make graph 
makeGraph(xij) 
wi = [] 
for node in range(len(g)): 
    wi.append(sum(g[node])) 
 
# we know 
# summation(wi)=2w 
w = sum(wi) / 2 
 
# the stationary distribution is 
# ui=(wi)/2w 
ui = [weight / (2 * w) for weight in wi] 
 
# H((wi)/2w)=H(ui) 
H_wi_div_2w = entropy(ui) 
 
# H(wij/2*w) = H(g[]/2*w) 
wij_div_2w_list = [] 
for i in range(len(g)): 
    wij_div_2w_list += [weight / (2 * w) for weight in g[i]] 
 
# H(wij/2*w) = H(wij_div_2w_list) 
H_wij_div_2w = entropy(wij_div_2w_list) 
 
# finally the entropy rate 
# H(x)=H(wij/2w)-H(wi/2w) 
H_x = H_wij_div_2w - H_wi_div_2w 
print('Entropy Rate: %.2f' % H_x)

---------------------------------------------------------------------------------------------
8.Write a program to find conditional entropy and join entropy and mutual information 
based on the following matrix.
##
##
# given 
import math 
 
matrix = [ 
    [1 / 8, 1 / 16, 1 / 32, 1 / 32], 
    [1 / 16, 1 / 8, 1 / 32, 1 / 32], 
    [1 / 16, 1 / 16, 1 / 16, 1 / 16], 
    [1 / 4, 0, 0, 0] 
] 
 
# the marginal distribution of x 
marginal_x = [] 
for i in range(len(matrix[0])): 
    marginal_x.append(sum(matrix[j][i] for j in range(len(matrix)))) 
 
# the marginal distribution of y 
marginal_y = [] 
for i in range(len(matrix)): 
    marginal_y.append(sum(matrix[i][j] for j in range(len(matrix[0])))) 
 
# H(x) 
def entropy(marginal_var): 
    H = 0 
    for x in marginal_var: 
        if x == 0: 
            continue 
        H += -(x * math.log2(x)) 
    return H 
 
H_x = entropy(marginal_x) 
H_y = entropy(marginal_y) 
 
# conditional entropy 
# H(x/y) 
H_xy = 0 

for i in range(len(matrix)):    
    tmp = [(1 / marginal_y[i]) * matrix[i][j] for j in range(len(matrix[0]))] 
    H_xy += entropy(tmp) * marginal_y[i] 
# H(y/x) 
H_yx = 0 
for i in range(len(matrix[0])): 
    tmp = [(1 / marginal_x[i]) * matrix[j][i] for j in range(len(matrix))] 
    H_yx += entropy(tmp) * marginal_x[i] 
print('Conditional Entropy H(x|y): ', H_xy) 
print('Conditional Entropy H(y|x): ', H_yx)  

# Joint entropy 
# H(x,y) 
H_of_xy = H_x + H_yx 
print('Joint Entropy H(x,y): ', H_of_xy) 

# Mutual Information 
# I(x,y) 
I_of_xy = H_y - H_yx 
print('Mutual Information: ', I_of_xy) 

--------------------------------------------------------------------------------------